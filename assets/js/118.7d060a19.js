(window.webpackJsonp=window.webpackJsonp||[]).push([[118],{1024:function(a,s,t){"use strict";t.r(s);var n=t(12),e=Object(n.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"title"}),t("p",[a._v("应聘岗位：Python 后端开发工程师"),t("br"),a._v("\n渠道：拉勾招聘"),t("br"),a._v("\n面试时间：2021-03-23 14:00\n面试地点：浙江省杭州市余杭区向往街 1008 号乐富海邦园 Q 座 9 层")])]),a._v(" "),t("p",[a._v("[TOC]")]),a._v(" "),t("h2",{attrs:{id:"面试流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试流程"}},[a._v("#")]),a._v(" 面试流程")]),a._v(" "),t("ol",[t("li",[a._v("填写面试登记表")]),a._v(" "),t("li",[a._v("做笔试题：python 基础、sql 基础、一道算法附加题")]),a._v(" "),t("li",[a._v("面试官：自我介绍、为什么打算离职、笔试题问答")])]),a._v(" "),t("h2",{attrs:{id:"面试题回忆"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#面试题回忆"}},[a._v("#")]),a._v(" 面试题回忆")]),a._v(" "),t("h3",{attrs:{id:"手写重试装饰器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#手写重试装饰器"}},[a._v("#")]),a._v(" 手写重试装饰器")]),a._v(" "),t("p",[a._v("带参数的装饰器应当是三层的，我当时忘记了，只写了两层，下面贴一下我在老项目里写的")]),a._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("retry")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("stop_max_attempt_number"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("int")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" wait_fixed"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("float")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" raise_exception"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[a._v('"""\n    方法重试装饰器\n    :param stop_max_attempt_number: 最大重试次数\n    :param wait_fixed: 重试间隔(单位秒）\n    :param raise_exception: 需要主动抛出的异常\n    """')]),a._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("decorator")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("func"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[a._v("@functools"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("wraps")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("func"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("wrapper")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("**")]),a._v("kw"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n            exception "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("None")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("stop_max_attempt_number"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("try")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" func"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v("args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("**")]),a._v("kw"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("except")]),a._v(" Exception "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                    exception "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" e\n                    time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("sleep"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("wait_fixed"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("raise")]),a._v(" raise_exception "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("or")]),a._v(" Exception"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("exception"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" wrapper\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" decorator\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br"),t("span",{staticClass:"line-number"},[a._v("12")]),t("br"),t("span",{staticClass:"line-number"},[a._v("13")]),t("br"),t("span",{staticClass:"line-number"},[a._v("14")]),t("br"),t("span",{staticClass:"line-number"},[a._v("15")]),t("br"),t("span",{staticClass:"line-number"},[a._v("16")]),t("br"),t("span",{staticClass:"line-number"},[a._v("17")]),t("br"),t("span",{staticClass:"line-number"},[a._v("18")]),t("br"),t("span",{staticClass:"line-number"},[a._v("19")]),t("br"),t("span",{staticClass:"line-number"},[a._v("20")]),t("br"),t("span",{staticClass:"line-number"},[a._v("21")]),t("br"),t("span",{staticClass:"line-number"},[a._v("22")]),t("br"),t("span",{staticClass:"line-number"},[a._v("23")]),t("br")])]),t("h3",{attrs:{id:"附加题-算法题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#附加题-算法题"}},[a._v("#")]),a._v(" 附加题-算法题")]),a._v(" "),t("p",[a._v("是一道困难难度的动态规划、记忆回溯题，原题是 "),t("a",{attrs:{href:"https://leetcode-cn.com/problems/word-break-ii/",target:"_blank",rel:"noopener noreferrer"}},[a._v("leetcode 140 单词拆分"),t("OutboundLink")],1),a._v(" 。因为我完全不会算法，也没有为了面试专门去准备算法题，所以这附加题没做。面试官说这题是技术总监设置的门槛，薪资要求比较高（面试登记表上有要求填写）的人必须做出来，面试官引导之后我还是做不出来，然后就直接被挂了，没有问到其他技术问题以及简历上的项目。")]),a._v(" "),t("h4",{attrs:{id:"leetcode-139-单词拆分-难度中等"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#leetcode-139-单词拆分-难度中等"}},[a._v("#")]),a._v(" leetcode 139.单词拆分——难度中等")]),a._v(" "),t("p",[a._v("地址：https://leetcode-cn.com/problems/word-break/")]),a._v(" "),t("p",[a._v("给定一个非空字符串 s 和一个包含非空单词的列表 wordDict，判定 s 是否可以被空格拆分为一个或多个在字典中出现的单词。")]),a._v(" "),t("p",[a._v("说明：")]),a._v(" "),t("ul",[t("li",[a._v("拆分时可以重复使用字典中的单词。")]),a._v(" "),t("li",[a._v("你可以假设字典中没有重复的单词。")])]),a._v(" "),t("p",[a._v("示例 1：")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('输入: s = "leetcode", wordDict = ["leet", "code"]\n输出: true\n解释: 返回 true 因为 "leetcode" 可以被拆分成 "leet code"。\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br")])]),t("p",[a._v("示例 2：")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('输入: s = "applepenapple", wordDict = ["apple", "pen"]\n输出: true\n解释: 返回 true 因为 "applepenapple" 可以被拆分成 "apple pen apple"。\n     注意你可以重复使用字典中的单词。\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br")])]),t("p",[a._v("示例 3：")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('输入: s = "catsandog", wordDict = ["cats", "dog", "sand", "and", "cat"]\n输出: false\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("p",[t("strong",[a._v("Python3 题解")]),a._v("\n题解地址：https://leetcode-cn.com/problems/word-break/solution/dong-tai-gui-hua-ji-yi-hua-hui-su-zhu-xing-jie-shi/")]),a._v(" "),t("p",[t("strong",[a._v("方法一：动态规划")]),a._v(" "),t("img",{attrs:{src:"https://pic.leetcode-cn.com/2a834dafa7bf590df1413fc742b07099854b6c6b842a5f7677564ccd044b5d69.png",alt:""}})]),a._v(" "),t("ol",[t("li",[a._v("初始化 dp=[False,...,False]，长度为 n+1。n 为字符串长度。dp[i] 表示 s 的前 i 位是否可以用 wordDict 中的单词表示。")]),a._v(" "),t("li",[a._v("初始化 dp[0]=True，空字符可以被表示。")]),a._v(" "),t("li",[a._v("遍历字符串的所有子串，遍历开始索引 i，遍历区间 [0,n)：\n"),t("ul",[t("li",[a._v("遍历结束索引 j，遍历区间 [i+1,n+1)：\n"),t("ul",[t("li",[a._v("若 dp[i]=True 且 s[i,...,j) 在 wordlist 中：dp[j]=True。解释：dp[i]=True 说明 s 的前 i 位可以用 wordDict 表示，则 s[i,...,j) 出现在 wordDict 中，说明 s 的前 j 位可以表示。")])])])])]),a._v(" "),t("li",[a._v("返回 dp[n]")])]),a._v(" "),t("p",[t("strong",[a._v("复杂度")])]),a._v(" "),t("ul",[t("li",[a._v("时间复杂度：O(n^2)")]),a._v(" "),t("li",[a._v("空间复杂度：O(n)")])]),a._v(" "),t("p",[t("strong",[a._v("Python代码")])]),a._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Solution")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("wordBreak")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("str")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" wordDict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" List"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("str")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("bool")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n        n "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n        dp "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n        dp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("True")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" j "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("i "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" n "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("dp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("and")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" wordDict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                    dp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("True")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" dp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br")])]),t("p",[t("strong",[a._v("方法二：记忆化回溯")])]),a._v(" "),t("ol",[t("li",[a._v("使用记忆化函数，保存出现过的 backtrack(s)，避免重复计算。")]),a._v(" "),t("li",[a._v("定义回溯函数 backtrack(s)")])]),a._v(" "),t("ul",[t("li",[a._v("若 s 长度为 0，则返回 True，表示已经使用 wordDict 中的单词分割完。")]),a._v(" "),t("li",[a._v("初试化当前字符串是否可以被分割 res=False")]),a._v(" "),t("li",[a._v("遍历结束索引 i，遍历区间 [1,n+1)：\n"),t("ul",[t("li",[a._v("若 s[0,...,i-1] 在 wordDict 中：res=backtrack(s[i,...,n-1]) or res。解释：保存遍历结束索引中，可以使字符串切割完成的情况。")]),a._v(" "),t("li",[a._v("返回 resres")])])])]),a._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[a._v("返回 backtrack(s)")])]),a._v(" "),t("p",[t("strong",[a._v("Python代码")])]),a._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" functools\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Solution")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("wordBreak")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("str")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" wordDict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" List"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("str")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("bool")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[a._v("@functools"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("lru_cache")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("back_track")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("not")]),a._v(" s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("True")]),a._v("\n            res "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("False")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" wordDict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                    res "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" back_track"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("or")]),a._v(" res\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" res\n\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" back_track"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br"),t("span",{staticClass:"line-number"},[a._v("12")]),t("br"),t("span",{staticClass:"line-number"},[a._v("13")]),t("br"),t("span",{staticClass:"line-number"},[a._v("14")]),t("br"),t("span",{staticClass:"line-number"},[a._v("15")]),t("br")])]),t("h4",{attrs:{id:"leetcode-140-单词拆分-ii-难度困难"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#leetcode-140-单词拆分-ii-难度困难"}},[a._v("#")]),a._v(" leetcode 140.单词拆分 II——难度困难")]),a._v(" "),t("p",[a._v("地址：https://leetcode-cn.com/problems/word-break-ii/")]),a._v(" "),t("p",[a._v("给定一个非空字符串 s 和一个包含非空单词列表的字典 wordDict，在字符串中增加空格来构建一个句子，使得句子中所有的单词都在词典中。返回所有这些可能的句子。")]),a._v(" "),t("p",[a._v("说明：")]),a._v(" "),t("ul",[t("li",[a._v("分隔时可以重复使用字典中的单词。")]),a._v(" "),t("li",[a._v("你可以假设字典中没有重复的单词。")])]),a._v(" "),t("p",[a._v("示例 1：")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('输入:\ns = "catsanddog"\nwordDict = ["cat", "cats", "and", "sand", "dog"]\n输出:\n[\n  "cats and dog",\n  "cat sand dog"\n]\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br")])]),t("p",[a._v("示例 2：")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('输入:\ns = "pineapplepenapple"\nwordDict = ["apple", "pen", "applepen", "pine", "pineapple"]\n输出:\n[\n  "pine apple pen apple",\n  "pineapple pen apple",\n  "pine applepen apple"\n]\n解释: 注意你可以重复使用字典中的单词。\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br")])]),t("p",[a._v("示例 3：")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('输入:\ns = "catsandog"\nwordDict = ["cats", "dog", "sand", "and", "cat"]\n输出:\n[]\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br")])]),t("p",[t("strong",[a._v("Python3 官方题解")]),a._v("\n题解地址：https://leetcode-cn.com/problems/word-break-ii/solution/dan-ci-chai-fen-ii-by-leetcode-solution/")]),a._v(" "),t("p",[t("strong",[a._v("前言")]),a._v("\n这道题是「139. 单词拆分」的进阶，第 139 题要求判断是否可以拆分，这道题要求返回所有可能的拆分结果。")]),a._v(" "),t("p",[a._v("第 139 题可以使用动态规划的方法判断是否可以拆分，因此这道题也可以使用动态规划的思想。但是这道题如果使用自底向上的动态规划的方法进行拆分，则无法事先判断拆分的可行性，在不能拆分的情况下会超时。")]),a._v(" "),t("p",[a._v("例如以下例子，由于字符串 s 中包含字母 b，而单词列表 wordDict 中的所有单词都由字母 a 组成，不包含字母 b，因此不能拆分，但是自底向上的动态规划仍然会在每个下标都进行大量的匹配，导致超时。")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('s = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa"\nwordDict = ["a","aa","aaa","aaaa","aaaaa","aaaaaa","aaaaaaa","aaaaaaaa","aaaaaaaaa","aaaaaaaaaa"]\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("p",[a._v("为了避免动态规划的方法超时，需要首先使用第 139 题的代码进行判断，在可以拆分的情况下再使用动态规划的方法进行拆分。相比之下，自顶向下的记忆化搜索可以在搜索过程中将不可以拆分的情况进行剪枝，因此记忆化搜索是更优的做法。")]),a._v(" "),t("p",[t("strong",[a._v("方法一：记忆化搜索")]),a._v("\n对于字符串 s，如果某个前缀是单词列表中的单词，则拆分出该单词，然后对 s 的剩余部分继续拆分。如果可以将整个字符串 s 拆分成单词列表中的单词，则得到一个句子。在对 s 的剩余部分拆分得到一个句子之后，将拆分出的第一个单词（即 s 的前缀）添加到句子的头部，即可得到一个完整的句子。上述过程可以通过回溯实现。")]),a._v(" "),t("p",[a._v("假设字符串 s 的长度为 n，回溯的时间复杂度在最坏情况下高达 O(n^n)。时间复杂度高的原因是存在大量重复计算，可以通过记忆化的方式降低时间复杂度。")]),a._v(" "),t("p",[a._v("具体做法是，使用哈希表存储字符串 s 的每个下标和从该下标开始的部分可以组成的句子列表，在回溯过程中如果遇到已经访问过的下标，则可以直接从哈希表得到结果，而不需要重复计算。如果到某个下标发现无法匹配，则哈希表中该下标对应的是空列表，因此可以对不能拆分的情况进行剪枝优化。")]),a._v(" "),t("p",[a._v("还有一个可优化之处为使用哈希集合存储单词列表中的单词，这样在判断一个字符串是否是单词列表中的单词时只需要判断该字符串是否在哈希集合中即可，而不再需要遍历单词列表。")]),a._v(" "),t("div",{staticClass:"language-py line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-py"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Solution")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("wordBreak")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("str")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" wordDict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" List"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("str")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" List"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("str")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[a._v("@lru_cache")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("backtrack")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("index"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" List"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("List"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("str")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" index "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n            ans "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("list")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("index "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                word "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("index"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" word "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" wordSet"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                    nextWordBreaks "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" backtrack"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n                    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" nextWordBreak "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" nextWordBreaks"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n                        ans"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("nextWordBreak"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("copy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("word"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" ans\n        \n        wordSet "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("set")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("wordDict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n        breakList "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" backtrack"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('" "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("join"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("words"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" words "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" breakList"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br"),t("span",{staticClass:"line-number"},[a._v("12")]),t("br"),t("span",{staticClass:"line-number"},[a._v("13")]),t("br"),t("span",{staticClass:"line-number"},[a._v("14")]),t("br"),t("span",{staticClass:"line-number"},[a._v("15")]),t("br"),t("span",{staticClass:"line-number"},[a._v("16")]),t("br"),t("span",{staticClass:"line-number"},[a._v("17")]),t("br"),t("span",{staticClass:"line-number"},[a._v("18")]),t("br")])]),t("p",[t("strong",[a._v("复杂度分析")]),a._v("\n本题的时间与空间复杂度均为指数级别，较难进行具体的分析。在最坏的情况下，考虑下面这样一组测试数据：")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v('s = "aaa...aaa"\nwordDict = ["a","aa","aaa", ..., "aaa...aaa"]\n')])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("p",[a._v("显然，s 的任意一种分隔方法均符合题目要求。即使我们忽略存储最终答案需要的空间，但在记忆化搜索的过程中缓存下来，防止重复计算而使用的空间不可以忽略。这一部分的占用的空间至少为 O(n * 2^n)，其中 n 是 s 的长度，即 s 的分隔方法有 2^n 种，每一种方法需要一个长度为 O(n) 的字符串进行存储。")]),a._v(" "),t("p",[a._v("对于时间复杂度部分，由于写入 O(n * 2^n) 空间至少也需要 O(n * 2^n) 的时间，因此时间复杂度同样为指数级别。")]),a._v(" "),t("p",[a._v("虽然记忆化搜索和普通的回溯方法的时间复杂度均为指数级别，但前者的底数为 2，后者的底数为 n，因此记忆化搜索仍然具有一定的优越性。")])])}),[],!1,null,null,null);s.default=e.exports}}]);